{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5664add2-9121-447b-b78c-9d2744aca60e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "30ddb9b8-25d6-488f-972f-c24e0cf7d8a7",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import regularizers as reg\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, GlobalAveragePooling2D, InputLayer, Dropout, SpatialDropout2D, BatchNormalization, Resizing, Rescaling, RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa12716-bce0-4d33-85df-08d9b88d5036",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "64367cf4-1b3e-45ae-a8f1-e63ba3cafbea",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# finue tune transfer learning model\n",
    "dense_net = DenseNet169(weights='imagenet', include_top=False, input_shape=None)\n",
    "\n",
    "for layer in dense_net.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b729466-8877-4140-81ac-706f39f89d36",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "ed9e6923-02a0-4b85-950a-49c1650d3f21",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# Images Dirs \n",
    "batch_size = 32\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe15066-c35a-4e48-8edf-d67c3d975066",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "d4c3a6f1-c8fe-4991-aaf5-cf3334bd4953",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 files belonging to 5 classes.\n",
      "Found 180 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Getting train , test , validate Images from our dirs \n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(200, 200),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "valid_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(200, 200),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ad1aa4-1f3a-45ad-9289-e9f7779d2a44",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "03d0b5e8-7d3a-4663-af9e-6bbb822395ca",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, None, None, 1664   12642880  \n",
      "                             )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1664)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               426240    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256)               1024      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13104197 (49.99 MB)\n",
      "Trainable params: 460549 (1.76 MB)\n",
      "Non-trainable params: 12643648 (48.23 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(dense_net)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256 , activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128 , activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23f53a8-b043-4c9a-a3bf-6e89dc5c422c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "c4032188-fa1b-42c6-b3f2-0946eeb9f62b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 16s 999ms/step - loss: 1.7143 - accuracy: 0.3321 - val_loss: 3.6362 - val_accuracy: 0.3667\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 3s 277ms/step - loss: 0.9609 - accuracy: 0.6241 - val_loss: 0.7148 - val_accuracy: 0.8389\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.6996 - accuracy: 0.7847 - val_loss: 0.9618 - val_accuracy: 0.7167\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.5872 - accuracy: 0.8102 - val_loss: 0.4208 - val_accuracy: 0.8833\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 2s 211ms/step - loss: 0.4668 - accuracy: 0.8467 - val_loss: 0.4297 - val_accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.3703 - accuracy: 0.9307 - val_loss: 0.5450 - val_accuracy: 0.7944\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.2949 - accuracy: 0.9453 - val_loss: 0.2135 - val_accuracy: 0.9333\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.2498 - accuracy: 0.9526 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 0.2039 - accuracy: 0.9635 - val_loss: 0.0898 - val_accuracy: 0.9722\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 0.1770 - accuracy: 0.9745 - val_loss: 0.1418 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.1501 - accuracy: 0.9891 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.1222 - accuracy: 0.9854 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.1184 - accuracy: 0.9745 - val_loss: 0.0414 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9889\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.0704 - accuracy: 0.9964 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0499 - accuracy: 0.9964 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_data, epochs=20, validation_data=valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2f15c8-3a0e-4699-b183-82ee5d3848e5",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "a4b210f0-98ea-4e22-90ac-90d871d807b0",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahmoudahmed/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1d77f-cf04-4d21-a7c0-f83788caa3bd",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "4c2b2bea-ac49-4a8c-9c9e-da0b21cc82e1",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "model = load_model('cnn_dense.h5')\n",
    "\n",
    "\n",
    "model_dict = {0: \"chris_evans\", 1: \"chris_hemsworth\", 2: \"mark_ruffalo\", 3: \"robert_downey_jr\", 4: \"scarlett_johansson\"}\n",
    "\n",
    "# Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(\"test.mp4\")\n",
    "\n",
    "while True:\n",
    "    _, frame = video_capture.read()    \n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (180, 180))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "           #Resizing into 128x128 because we trained the model with this image size.\n",
    "        img_array = np.array(im)\n",
    "                    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "                    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)[0]\n",
    "        maxindex = int(np.argmax(pred))\n",
    "        print(maxindex)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        print(pred[maxindex])\n",
    "        if pred[maxindex] > .4:\n",
    "            name = model_dict[maxindex]\n",
    "#         if(pred[0][3]>0.3):\n",
    "            \n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
